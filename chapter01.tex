% !TEX encoding = UTF-8 Unicode
%!TEX root = thesis.tex
% !TEX spellcheck = en-US
%%=========================================
\newpage
\chapter{Approaches for Detecting Robots \\ in Social Media}
%% NOCH EIN KAPITEL: "VIEWED SOCIAL MEDIA PLATTFORMS"? -> erkläre hier betrachtete social media plattformen kurz damit man später weiß wovon man redet?

\section*{Management Summary}
This is the management summary blablabla mhmhm...

\section{Introduction}
Software robots are often called bot. <- muss hier irgendwie rein 

\section{Definition and History of Social Bots} 
This section will introduce the term social bot formally and give a short overview about the beginning and the development of this topic.

In order to be able to discuss social media bot detection, we need a clear understanding of what social bots actually are.  For that, we use the definition given by Ferrara et al. in their article The Rise of Social Bots:
\begin{quote}
	"A social bot is a computer algorithm that automatically produces content and interacts with humans on social media, trying to emulate and possibly alter their behavior." \cite{ferrara15}
\end{quote}

The root of of social bots, or just bots how we will sometimes call them here as well, can probably be found in the Turing test, developed by Alan Turing in 1950 \cite{turing}. It involves three parties, two of which are human and one is a computer program. While one human is having a conversation with the software, it is the task of the other human to identify the program. If he is not able to do so, the software is passing the Turing test. This led to the development of a lot of so called chatbots, which just aimed to appear as human as possible in a conversation.  

A rather famous and often cited example for such a chatbot is ELIZA, introduced by Joseph Weizenbaum 1966 in \cite{eliza}. It mimicked a psychotherapist and showed \mbox{that -- at} least some kind\\ \mbox{ of -- communication} between a human and a computer is possible.

Since then, a lot of things have changed. Today, bots are a lot more than bare entertainment or proof of concept. With the triumph of the Internet and especially social networks like Facebook and Twitter, the possible use cases for social bots have increased dramatically. While they were initially mostly used to simply post content, today they are able to credibly interact with each other and even humans \cite{boshmaf13, hwang12}. As we will see in the next section, nowadays bots are used to spread messages, for marketing and a lot more.


\section{Why is Bot Detection in Social Media Important?}
\begin{itemize}
	\item Information flood -> need to get the message through
	\item influence political mood
	\item marketing
	\item false information (boston marathon: cassa 2013)
	\item seem fame
	\item stock exch..
\end{itemize}
---> section "engineered social tampering" and following in the rise of social bots!! 

+ Key Challenges in Defending Against Malicious Socialbots \cite{boshmaf12}
\section{Social Bot Detection Approaches}
In this chapter we want to introduce several techniques for detecting social bots. Based on Ferrara et al. \cite{ferrara15} we distinguish between three detection approach classes. 

The first category of detection approaches is based on social network information. They are also called graph-based, since they map users and their relations into a graph and then try to identify bots in the hereby obtained social network by means of graph theory. 

Afterwards we will discuss crowd-sourcing based social bot detection approaches. They use actual humans to detect bots, assuming that the human ability to notice details in communication will make this an easy task.

The last category we want to elaborate on are detection approaches based on machine learning. Mechanisms that make use of this approach try to observe behavioral patterns that are typical for social bots. Since these patterns are encoded in so called patterns, this approach is also known as feature-based \cite{ferrara15}. %%IS THIS CITATION NEEDED? ALREADY SAID IN FIRST PARAGRAPH(BASED ON...)


In the following sub sections, we will go into detail about each of these three approaches and illustrate them using real detection systems.

\subsection{Based on Social Network Information}
A term that is often used in combination with detection of bots by using social networks is sybil or the sybil attack. It was presented as a thread to distributed systems by John R. Douceur in \cite{sybil}. In the specific context of social media platforms when conducting a sybil attack, an attacker creates a large amount of fake identities in a system to the point where these identities make up a considerable fraction of the system's whole user base. When this is achieved, the attacker can influence the whole system and control its contents to a certain degree. A sybil, sybil node or sybil account is therefor simply one of the fake entities, or, depending on the attack architecture, just a social bot. It is not hard to see that social bot detection can, more specifically, be viewed as a defense against the sybil attack.   

The general proceeding of social network based bot detection approaches is rather simple. They map the users base of the social platform they aim to defend into a social graph, where a node is corresponding to a user and an edge between two nodes exists if there is a specific kind of relationships between the two respective users on the platform. The nodes can be hereby be distinguished in sybil nodes, respectively bots, and non-sybil nodes, respectively legitimate users. The goal of the detection approach is now, to identify whether a given node is a sybil or not \cite{comparison}.

There are a number of proposed social network based sybil detection schemes like for example SybilGuard \cite{sybilguard}, SybilInfer \cite{sybilinfer} or SumUp \cite{sumup}. While they all have different assumptions and use varying algorithms to achiever their goal, Viswanath et al. show in \cite{comparison}, that, at a high level, all of them work by them same principles.

Basically they can be viewed as graph partitioning algorithms, which partition a given graph into multiple disjoint subgraphs. As already mentioned above, ideally two subgraphs are assembled, one that contains only sybil nodes and one that contains only non-sybil nodes. Since a clear distinction is often hard to make, the approaches basically assign a rank to each node and decide afterwards, depending on several parameters, which ranks are classified as sybil and which as non-sybil. It is thereby obvious, that the ranking algorithm is crucial for the whole scheme. Though, of course, the ranking algorithms for the different detection schemes are differing, they generally have in common, that they base their rating on how tightly connected the respective node is to a known trusted node. Thus, they work by detecting local communities of nodes. In other words closely connected groups of nodes \cite{comparison}.

It is not hard to see, that these algorithms are therefor easy to deceive. If an attacker is able to establish so called attack edges, connections between his sybil nodes and non-sybil nodes which are connected to a trusted community, it gets significantly harder to identify the bots. A common assumption is that these attack edges are hard to create \cite{sybilguard}, which means, that legitimate users tend not to establish social network connections to social bots. However, Boshmaf et al. show in \cite{boshmaf11} that this assumption is to be questioned. 
They tried to infiltrate the social media platform Facebook with a large number of sybil accounts and tried to establish connections to real users. The average acceptance rate of their relationship requests came to about 20\% and could be increased to 80\% depending on how many indirect relationships between the sybil and the user already existed \cite{boshmaf11}. %%FACEBOOK / TWITTER etc. zitieren?

A well known example for a bot detection approach that is based on social network information is the Facebook Immune System (IMS) \cite{fis}. This system aims to defend the social media platform Facebook and its users not only against sybil attacks but also to prevent spam, malware distribution, phishing and so on.  To achieve this goal, it takes a lot more actions than the above described general approach for social network based detection schemes. The IMS runs checks on every action performed on Facebook in realtime in order to give attackers as less time as possible to accomplish there goals and to react. It classifies these actions according to predefined policies and makes it thereby possible to judge them and the corresponding users.

An example for this could be a newly created Facebook account, that sends a lot of friendship requests. These are used in Facebook to establish relationships between users. A legitimate user starts sending friendship requests usually mainly to people he knows and vice versa, that is, people that are likely to accept his friendship request. If a lot of these requests are now declined, this could be a indication for the system that the sending user might not be legitimate.  The IMS also makes heavy use of machine learning, which we will discuss later on, and generates training data automatically in order to adapt to the fast changing attacks and user behavior \cite{fis}.

\subsection{Based on Crowd-Sourcing}


\subsection{Based on Machine Learning Methods}
wie misuse based ids!

\section{Summary and Outlook}


























\newpage